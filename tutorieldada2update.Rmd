---
title: "Tutoriel DADA2"
output: github_document
Fait par: Toky Emmanuel Rabemanana Rahaga
---

```{r}

#Importation du package dada2 pour l'analyse des données de séquençage

library(dada2)
packageVersion("dada2")
```

```{r}

# Spécification du chemin du répertoire où se trouvent les fichiers fastq

path <- "/home/rstudio/Tutorieldada2update/MiSeq_SOP"

#verification si tout le repertoire est bien present

list.files(path)
```


```{r}

#Extraire les fichiers FASTQ de lecture avant (R1) dont le nom contient _R1_001.fastq" puis pareil avec R2

fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))

# Obtention des noms des échantillons en récupérant la première partie du nom de fichier, en les séparant par le caractère '_'

sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```
```{r}

# Génération d'un graphique des profils de qualité pour les deux premiers fichiers R1

plotQualityProfile(fnFs[1:2])
```
```{r}

# Génération d'un graphique des profils de qualité pour les deux premiers fichiers R2

plotQualityProfile(fnRs[1:2])
```
```{r}
# Définition des chemins: des fichiers filtrés pour les premières lectures (R1) en les nommant avec "_F_filt.fastq.gz".

filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))

#Définition des chemins: des fichiers filtrés pour les secondes lectures (R2) en les nommant avec "_R_filt.fastq.gz"

filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))

#Attribution des noms d'échantillons aux fichiers filtrés R1 et R2 afin de faciliter le suivi.

names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

```{r}

#->Filtrage et de nettoyage multiparamètres des séquences FASTQ pour plusieurs échantillons 

##-> la longueur de coupe : les séquences avant (fnFs) sont tronquées à 240 bases, tandis que les séquences arrière (fnRs) le sont à 160 bases. De plus, le seuil d'erreur maximal est fixé à maxEE=(2,2), ce qui signifie que les séquences avec plus de 2 erreurs cumulées seront éliminées. Si une séquence contient une base N, elle sera également rejetée (maxN=0). Les bases avec un score de qualité inférieur à 2 (truncQ=2) seront coupées ou supprimées. Les séquences de phix seront retirées (rm.phix=true), et les fichiers filtrés seront compressés au format gzip (compress=True). Enfin, la variable out stocke le résultat de la fonction filterAndTrim(), qui fournit un tableau avec des informations sur le nombre de séquences avant et après le filtrage

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```
```{r}
#Évaluer les erreurs dans les séquences avant à partir des fichiers filtrés

##->DADA2 développe un modèle d'erreur pour les séquences avant afin de corriger les erreurs de séquençage. Pour ce faire, elle s'appuie sur les séquences filtrées (contenues dans filtFs) pour estimer les erreurs typiques de séquençage, telles que les substitutions et les insertions. errF est l'objet qui contient le modèle d'erreur appris pour les séquences avant

errF <- learnErrors(filtFs, multithread=TRUE)
```
```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```
```{r}
plotErrors(errF, nominalQ=TRUE)
```
```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```
```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```
```{r}
dadaFs[[1]]
```
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```
```{r}
#Construct sequence table
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
```{r}
#Remove chimeras
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
```{r}
sum(seqtab.nochim)/sum(seqtab)
```
```{r}
#Track reads through the pipeline
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
```{r}
#Assign taxonomy
taxa <- assignTaxonomy(seqtab.nochim, "/home/rstudio/Tutorieldada2update/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
```
```{r}
taxa <- addSpecies(taxa, "/home/rstudio/Tutorieldada2update/silva_species_assignment_v132.fa.gz")
```
```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```
```{r}
library(DECIPHER); packageVersion("DECIPHER")
```
```{r}
#autre alternative utilisation classifier par des sifer
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
load("/home/rstudio/Tutorieldada2update/SILVA_SSU_r138_2019.RData") # CHANGE TO THE PATH OF YOUR TRAINING SET
ids <- IdTaxa(dna, trainingSet, strand="top", processors=NULL, verbose=FALSE) # use all processors
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species") # ranks of interest
# Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
taxid <- t(sapply(ids, function(x) {
        m <- match(ranks, x$rank)
        taxa <- x$taxon[m]
        taxa[startsWith(taxa, "unclassified_")] <- NA
        taxa
}))
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(seqtab.nochim)
```
```{r}
#Evaluate accuracy
unqs.mock <- seqtab.nochim["Mock",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```

```{r}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```
#Bonus: Handoff to phyloseq
```{r}
library(phyloseq); packageVersion("phyloseq")
```
```{r}
library(Biostrings); packageVersion("Biostrings")
```
```{r}
library(ggplot2); packageVersion("ggplot2")
```
```{r}
theme_set(theme_bw())
```
```{r}
samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, "D"), `[`, 1)
gender <- substr(subject,1,1)
subject <- substr(subject,2,999)
day <- as.integer(sapply(strsplit(samples.out, "D"), `[`, 2))
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)
samdf$When <- "Early"
samdf$When[samdf$Day>100] <- "Late"
rownames(samdf) <- samples.out
```
```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample
```
```{r}
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps
```
#Visualize alpha-diversity:
```{r}
plot_richness(ps, x="Day", measures=c("Shannon", "Simpson"), color="When")
```
#Ordinate:
```{r}
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")
```
```{r}
plot_ordination(ps.prop, ord.nmds.bray, color="When", title="Bray NMDS")
```
#Bar plot:
```{r}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Day", fill="Family") + facet_wrap(~When, scales="free_x")
```








